{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Today we become data scientists** #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CONTRIBUTORS #\n",
    "\n",
    "This in-class exercise is to be done in pairs. Add the names of the two students in this text block.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Workflow for today\n",
    "\n",
    "Today we will work in both numpy and pytorch to learn the basics of fitting models to data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Today:* Today we are going to do two things:\n",
    "1. Implement least squares using numpy and get a feel for how polynomial regression works.\n",
    "2. Implement the same model in PyTorch and get a feel for what we lose when we use backprop."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A first toy fit #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First I will give you a basic working example for how to fit a linear function:\n",
    "$y(x) = A + B x$\n",
    "to data. Your job will be to turn this into general purpose code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**First generate data.** I'm going to generate data for a linear function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ndatapoints = 20\n",
    "x = np.linspace(0, 1, Ndatapoints)\n",
    "y = 2*x + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Build matrices.** Next I am going to generate the two matrices we derived in class\n",
    "$$\\mathbf{P} = \\left\\{x^i_d\\right\\}_{id}$$\n",
    "$$\\mathbf{M} = \\left\\{\\sum_d x^i_d x^j_d \\right\\}_{ij}$$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "Pmatrix = np.zeros((Ndatapoints, 2)) # allocate with the correct shape then fill in\n",
    "Pmatrix[:, 0] = 1\n",
    "Pmatrix[:, 1] = x\n",
    "\n",
    "Mmatrix = np.zeros((2, 2))           # allocate with the correct shape then fill in\n",
    "Mmatrix[0, 0] = np.dot(Pmatrix[:, 0], Pmatrix[:, 0])\n",
    "Mmatrix[0, 1] = np.dot(Pmatrix[:, 0], Pmatrix[:, 1])\n",
    "Mmatrix[1, 0] = np.dot(Pmatrix[:, 1], Pmatrix[:, 0])\n",
    "Mmatrix[1, 1] = np.dot(Pmatrix[:, 1], Pmatrix[:, 1])\n",
    "\n",
    "# Here is a more compact way to do the same thing using a for loop\n",
    "Mmatrix = np.zeros((2, 2))\n",
    "for i in range(2):\n",
    "    for j in range(2):\n",
    "        Mmatrix[i, j] = np.dot(Pmatrix[:, i], Pmatrix[:, j])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solve least squares problem.** Finally, we build and solve the two systems in order to get the coefficients A and B. To do this we will use some functions from numpy - `np.dot` and `np.linalg.solve`. Use an LLM to get an explanation for how these should be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Either we can build and solve the matrix equation directly\n",
    "alpha = np.linalg.solve(Mmatrix,np.dot(Pmatrix.T,y))\n",
    "\n",
    "# or we can use numpys built in least squares solver\n",
    "alpha = np.linalg.lstsq(Pmatrix, y, rcond=None)[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Make plot of the final results.** Finally, we'll confirm that our model fit recovers the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xfit = np.linspace(0, 1, 100)\n",
    "yfit = alpha[0] + alpha[1]*xfit\n",
    "plt.figure()\n",
    "plt.plot(x, y, 'o', label='Data')\n",
    "plt.plot(xfit, yfit, label='Fit')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In what follows, you will adapt this toy code into a reusable class, and then use that class to do some experiments and understand how models work as we vary the amount of available data and the size of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building up a few datasets #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will define functions to generate a few datasets that we'll use throughout today's exercise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Noisy linear function.** \n",
    "Build up a function that samples N random points on the unit interval. Evaluate the function\n",
    "$$y(x) = 2 x + \\epsilon$$\n",
    "where $\\epsilon$ is sampled from a normal distribution with zero mean and standard deviation 0.2. You will find the functions `np.random.rand` and `np.random.normal` to be useful. The function should return a set of N pairs of x,y values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "def generate_noisylinear_data(N):\n",
    "    # modify function here\n",
    "    return np.zeros(N),np.zeros(N)\n",
    "\n",
    "# Test the function\n",
    "plt.plot(generate_noisylinear_data(10)[0],generate_noisylinear_data(10)[1],'o')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Polynomial function.** Generate N points uniformly spaced on the unit interval (Hint: you should use `np.linspace`) and evaluate the cubic polynomial:\n",
    "$$y(x) = x^3 - 2*x^2 + x - 4$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "def generate_polynomial_data(N):\n",
    "    # modify function here\n",
    "    return np.zeros(N),np.zeros(N)\n",
    "\n",
    "# Test the function\n",
    "plt.plot(generate_polynomial_data(10)[0],generate_polynomial_data(10)[1],'o')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Continuous function.** Generate N points uniformly spaced on the unit interval, and evaluate the function:\n",
    "$$y(x) = \\sin 2 \\pi x$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "def generate_smoothfunction_data(N):\n",
    "    # modify function here\n",
    "    return np.zeros(N),np.zeros(N)\n",
    "\n",
    "# Test the function\n",
    "plt.plot(generate_smoothfunction_data(10)[0],generate_smoothfunction_data(10)[1],'o')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Discontinuous function.** Generate N points uniformly spaced on the unit interval, and have them evaluate the function:\n",
    "$$ y(x) =\n",
    "\\begin{cases} \n",
    "0 & \\text{if } x < \\frac12 \\\\\n",
    "1 & \\text{if } x \\geq \\frac12 \n",
    "\\end{cases}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "def generate_stepfunction_data(N):\n",
    "    # modify function here\n",
    "    return np.zeros(N),np.zeros(N)\n",
    "\n",
    "# Test the function\n",
    "plt.plot(generate_stepfunction_data(10)[0],generate_stepfunction_data(10)[1],'o')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your turn.** Copy and paste images of all four functions here so that we can confirm you've generated 4 datasets to experiment with."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Put stuff here.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate a general purpose least squares solver #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building up a least squares solver is relatively straightforward, although the math is a little annoying. I'm going to step you through how to build up a class which will fit a polynomial to a given dataset. A skeleton for a `polyFitter` class is given below "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class polyFitter:\n",
    "    def __init__(self, polyorder, dataset):\n",
    "        self.polyorder = polyorder # the order of the polynomial to fit\n",
    "        self.dataset = dataset     # the dataset to be fitted\n",
    "        self.solved = False        # a flag to indicate if the polynomial has been fitted\n",
    "        self.coeffs = None         # the coefficients of the fitted polynomial, set to None if not fit yet\n",
    "        \n",
    "    def fit(self):\n",
    "        # this is where we will build and solve the least squares problem\n",
    "        #\n",
    "        #\n",
    "        \n",
    "        self.solved = True                        # when finished we set the solved flag to True\n",
    "        self.coeffs = np.zeros(self.polyorder+1)  # and set the coeffs to the solution\n",
    "        return self.coeffs\n",
    "\n",
    "    def evalfit(self):\n",
    "        # after the model has been fit, we can evaluate it at any point x\n",
    "        if not self.solved:\n",
    "            print(\"Error: model not yet fit\")\n",
    "            return None\n",
    "        else:\n",
    "            # put stuff here\n",
    "            return 0\n",
    "    \n",
    "    def plot(self):\n",
    "        # generate a plot of the data and the fit. \n",
    "        # make sure to check that the model has been fit first!\n",
    "        return 0\n",
    "\n",
    "# Example usage - when you run this cell you should recover my example from the beginning\n",
    "Ndatapoints = 20\n",
    "x = np.linspace(0, 1, Ndatapoints)\n",
    "y = 2*x + 1\n",
    "fitToData = polyFitter(1, (x,y))\n",
    "print(fitToData.fit()) # This should print [1., 2.]\n",
    "fitToData.plot()       # This should plot the data and the fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 1.** We will first reproduce the example I gave at the beginning of the notebook, and make sure that our class generates the same behavior. Copy and paste the code to build the matrices and solve the least square problem into the evalfit function.\n",
    "**Step 2.** Fix the interface. Make sure that all of the functions are pointing to the right things.\n",
    "\n",
    "Take a stab at this. After a little while Prof. Trask will help you flesh this out on the projector, but we will continue to wrap bits of jupyter notebook in reusable classes as we continue the semester. It will be tough at first, but easy as you practice it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiments! #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will do a series of experiments now to understand the interplay between the degree of the polynomial space and the amount of data. In lecture we discussed the complexity/data tradeoff - for a very powerful model we need enough data or the model will \"overfit\". I'll guide you through a series of experiments. First, we're going to build a little piece of code to visualize all of the choices of n (polynomial order) and N (number of data points)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this will plot a 3x3 grid of y = sin(2*pi*(n+m)x), where the row is n and the column is m\n",
    "list_of_functions1 = [np.sin(2.*(0+m)*x) for m in range(3)]\n",
    "list_of_functions2 = [np.sin(2.*(1+m)*x) for m in range(3)]\n",
    "list_of_functions3 = [np.sin(2.*(2+m)*x) for m in range(3)]\n",
    "\n",
    "# Create a 3x3 grid of subplots\n",
    "fig, axes = plt.subplots(3, 3, figsize=(15, 15))\n",
    "\n",
    "# plot the first row\n",
    "for i in range(3):\n",
    "    ax = axes[0, i]\n",
    "    ax.plot(x, list_of_functions1[i])\n",
    "    ax = axes[1, i]\n",
    "    ax.plot(x, list_of_functions2[i])\n",
    "    ax = axes[2, i]\n",
    "    ax.plot(x, list_of_functions3[i])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your turn.** This will be a more open ended exercise now. Your task is to generate a grid of plots exploring number of data in each row and number of monomials in each column. Repeat this for each of the different representative types of functions. To complete this task, it may take you 10-30m depending on your comfort level with Python.\n",
    "\n",
    "In a markdown block below, describe qualitatively how the different functions respond differently. For which functions can you postulate a rule for how big of an n you can pick for a given N?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A babystep in PyTorch #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll continue on Monday how to use PyTorch in the same setting and do some more experiments. For now, the following code snippet will repeat the initial objective of fitting y(x) = A + B*x to some data. To get warmed up (and check if you can get pytorch working) run the following pytorch code that will reproduce the first experiment we did today. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Define the model (in our case, its y = A*x + b)\n",
    "class LinearFitLayer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LinearFitLayer, self).__init__()\n",
    "        # Random guess for parameters A and B\n",
    "        self.A = nn.Parameter(torch.randn(1))\n",
    "        self.B = nn.Parameter(torch.randn(1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.A * x + self.B\n",
    "\n",
    "# Create a dataset\n",
    "Ndatapoints = 20\n",
    "x = np.linspace(0, 1, Ndatapoints)\n",
    "y = 2*x + 1\n",
    "\n",
    "# Convert the data to PyTorch tensors\n",
    "x_data = torch.tensor(x, dtype=torch.float32,requires_grad=True)\n",
    "y_data = torch.tensor(y, dtype=torch.float32,requires_grad=True)\n",
    "\n",
    "# Instantiate the custom layer\n",
    "layer = LinearFitLayer()\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(layer.parameters(), lr=0.01)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 5000\n",
    "for epoch in range(num_epochs):\n",
    "    # Forward pass\n",
    "    outputs = layer(x_data)\n",
    "    loss = criterion(outputs, y_data)\n",
    "    \n",
    "    # Backward pass and optimization\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    if (epoch+1) % 100 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "# Print learned parameters\n",
    "print(f'Learned parameter A: {layer.A.item()}')\n",
    "print(f'Learned parameter B: {layer.B.item()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jumpstart on the homework #"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you happen to get this far during lecture today - great job! In this weeks homework, due a week from Monday, we will be using pytorch and least squares to fit a model to the data that came out of the rock paper scissors code. You can get a jump start on your homework by generating 20 simulations from your code and saving them to disk."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Turning in assignments on Canvas #\n",
    "In order to submit your assignment as a pair, you need to create a group on Canvas. This will enable you to both receive the same grade for one submission.\n",
    "\n",
    "On Canvas, navigate to People > Groups > In-Class 13.\n",
    "Find an empty group and add the names of both members of the pair.\n",
    "\n",
    "Submit your work as both an ipynb and a pdf to Canvas.\n",
    "\n",
    "Save the ipynb and upload from your hard drive. Also print a pdf file to ensure the graders can see you have completed the exercise, even if there are issues with the formatting in your jupyter notebook.\n",
    "\n",
    "The student who did not submit should make sure that the group was created successfully by checking that they can also access the files on their Canvas page."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
